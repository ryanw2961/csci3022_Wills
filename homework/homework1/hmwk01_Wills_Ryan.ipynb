{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Data Cleaning and Exploratory Data Analysis \n",
    "***\n",
    "\n",
    "**Name**: \n",
    "\n",
    "***\n",
    "\n",
    "This assignment is due on Moodle by **5pm on Friday September 14th**. Your solutions to theoretical questions should be done in Markdown directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.   \n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Unless a url is given for a data set, you will find the required data in the same directory as this assignment on GitHub.\n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Remember that there is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Piazza on writing math in Markdown. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 \n",
    "***\n",
    "\n",
    "Rebecca cares about [octopuses](https://english.stackexchange.com/questions/270/what-is-the-correct-plural-of-octopus/271). She cares so much that, up and down the coast, she opens octopus rescues, octopus temporary housing, and octopus sanctuaries, specifically targeted at juveniles in need. For convenience, we will refer to all the Juvenile Octopus Rescues, Temps, and Sanctuaries as \"JORTS.\"\n",
    "\n",
    "Rebecca wants to estimate the average food consumption across the JORTS this month so that she can plan the food orders for next month. She has 14 Rescues, 35 Temporary houses, and 56 Sanctuaries. What an empire!\n",
    "\n",
    "Rebecca opens up the *JORTS Manager App* on her phone, which gives her a list of all of her coastal operations. She randomly picks 15 of them, and gets ready to email their managers asking for the monthly food reports. Of course, Rebecca has taken CSCI 3022, so she knows a thing or two about sampling, and so, to get a good estimate of the monthly food consumption (kilograms per month) for typical JORTS, she intentionally chooses 2 Rescues, 5 Temporary houses, and 8 Sanctuaries.\n",
    "\n",
    "Identify the following: \n",
    "\n",
    "- the population \n",
    "- the sample frame \n",
    "- the sample \n",
    "- the type of sample \n",
    "- the quantity of interest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers:\n",
    "***\n",
    "- The population is the JORTS.\n",
    "\n",
    "- The sample frame would be the JORTS Manager App from her phone.\n",
    "\n",
    "- The sample is the 15 random coastal operations.\n",
    "\n",
    "- The sample type is a stratified sample.\n",
    "\n",
    "- The quantity of interest is the monthly food consumption (kilos per month)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 \n",
    "***\n",
    "\n",
    "A method to investigate the sensitivity of the sample mean and the sample median to extreme outliers and changes in the dataset is to replace one or more elements in a given dataset by a number $y$ and investigate the eï¬€ect when $y$ changes. To illustrate this, consider the dataset\n",
    "\n",
    "$$\n",
    "4.6 \\quad \n",
    "5.0 \\quad\n",
    "6.5 \\quad\n",
    "7.7 \\quad\n",
    "y \\quad\n",
    "4.2 \\quad\n",
    "1.9\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Compute the sample mean and sample median for $y=0$. Compute them both again for $y=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.27142857143\n",
      "4.6\n"
     ]
    }
   ],
   "source": [
    "y = 0\n",
    "x = np.array([4.6, 5.0, 6.5, 7.7, y, 4.2, 1.9], dtype = float)\n",
    "print(np.mean(x))\n",
    "print(np.median(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.7\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "y = 10\n",
    "x = np.array([4.6, 5.0, 6.5, 7.7, y, 4.2, 1.9], dtype = float)\n",
    "print(np.mean(x))\n",
    "print(np.median(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: What should $y$ be if we want the mean to be equal to $10$? What should $y$ be if we want the mean to be equal to $0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.1\n"
     ]
    }
   ],
   "source": [
    "y = 0\n",
    "x = np.array([4.6, 5.0, 6.5, 7.7, y, 4.2, 1.9])\n",
    "print(70-(np.sum(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "y = 40.1\n",
    "x = np.array([4.6, 5.0, 6.5, 7.7, y, 4.2, 1.9], dtype = float)\n",
    "print(np.mean(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.22044604925e-15\n"
     ]
    }
   ],
   "source": [
    "y = -29.9\n",
    "x = np.array([4.6, 5.0, 6.5, 7.7, y, 4.2, 1.9], dtype = float)\n",
    "print(np.sum(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Compute the sample median for the following cases: \n",
    "- $y=10$ \n",
    "- $y=100$ \n",
    "- $y \\to \\infty$ \n",
    "- $y=5.01$ \n",
    "- $y=4.99$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "y = 10\n",
    "x = np.array([4.6, 5.0, 6.5, 7.7, y, 4.2, 1.9], dtype = float)\n",
    "print(np.median(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "y = 100\n",
    "x = np.array([4.6, 5.0, 6.5, 7.7, y, 4.2, 1.9], dtype = float)\n",
    "print(np.median(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "y = math.inf\n",
    "x = np.array([4.6, 5.0, 6.5, 7.7, y, 4.2, 1.9], dtype = float)\n",
    "print(np.median(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "y = 5.01\n",
    "x = np.array([4.6, 5.0, 6.5, 7.7, y, 4.2, 1.9], dtype = float)\n",
    "print(np.median(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.99\n"
     ]
    }
   ],
   "source": [
    "y = 4.99\n",
    "x = np.array([4.6, 5.0, 6.5, 7.7, y, 4.2, 1.9], dtype = float)\n",
    "print(np.median(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Think about the previous parts, above, and describe in words or mathematical notation the answers to the following two questions:\n",
    "\n",
    "- By varying $y$, what is the set of all the possible values that the sample mean could take on?\n",
    "- By varying $y$, what is the set of all the possible values that the sample median could take on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part D Answer\n",
    "\n",
    "By varying y, the mean can be any set of possible values.\n",
    "\n",
    "By varying y, the set of possible values for the median must be in the range from 4.6 to 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 \n",
    "***\n",
    "\n",
    "Let $x_1, x_2, \\ldots, x_n$ be $n$ observations of a variable of interest.  Recall that the sample mean $\\bar{x}_n$ and sample variance $s^2_n$ are given by \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\frac{1}{n}\\sum_{k=1}^n x_k \\quad \\textrm{and} \\quad s^2_n = \\frac{1}{n-1}\\sum_{k=1}^n \\left( x_k - \\bar{x}_n\\right)^2\n",
    "$$\n",
    "\n",
    "where here the subscript $n$'s indicate the number of observations in the sample. Notice that a natural computation of the variance requires two passes over the data: one to compute the mean, and a second to subtract the mean from each observation and compute the sum of squares. It is often useful to be able to compute the variance in a single pass, inspecting each value $x_k$ only once; for example, when the data are being collected without enough storage to keep all the values, or when costs of memory access dominate those of computation. In this problem you will explore two methods for such an _online_ computation of the mean and variance.  \n",
    "\n",
    "**Part A**: Show algebraically that the following relation holds between the mean of the first $n-1$ observations and the mean of all $n$ observations: \n",
    "\n",
    "$$\n",
    "\\bar{x}_n = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$\n",
    "\\bar{x}_n = \\frac{1}{n}\\sum_{k=1}^n x_k = \\bar{x}_{n-1} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "$\n",
    "\n",
    "$\n",
    "\\frac{1}{n}\\sum_{k=1}^n x_k = \\frac{x_1+x_2+...+x_{n-1}+x_n}{n} = \\frac{x_n}{n}\n",
    "$\n",
    "\n",
    "$\n",
    " \\bar{x}_{n-1} = \\frac{x_1+x_2+...+x_{n-1}}{n} \n",
    "$\n",
    "\n",
    "$\n",
    "\\bar{x}_n = \\frac{x_1+x_2+...+x_{n-1}}{n} + \\frac{x_n - \\bar{x}_{n-1}}{n}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Write a function `my_sample_mean` that takes as its input a numpy array and returns the mean of that numpy array using the formulas from class (written above). You may *not* use numpy's built in mean function. Write another function `my_sample_var` that takes as its input a numpy array and returns the variance of that numpy array, again using the formulas from class (written above). You may *not* use any built-in sample variance functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_sample_mean(a):\n",
    "    total = np.sum(a)\n",
    "    average = total/len(a)\n",
    "    return average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_sample_var(b):\n",
    "    total = np.sum(b)\n",
    "    temp = (total - my_sample_mean(b))**(2)\n",
    "    var = temp/(len(b) - 1)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Use your functions from Part B to compute the sample mean and sample variance of the following array, which contains the counts of perfectly round suckers found on a set of aquarium octopuses.\n",
    "\n",
    "`octopus_suckers = [25, 29, 40, 19, 7, 6, 3, 11, 19, 21, 22, 45, 27]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean is: 21.0769230769\n",
      "21.0769230769\n",
      "Variance is: 5330.84023669\n",
      "146.686390533\n"
     ]
    }
   ],
   "source": [
    "octopus_suckers = [25, 29, 40, 19, 7, 6, 3, 11, 19, 21, 22, 45, 27]\n",
    "print(\"Mean is:\", my_sample_mean(octopus_suckers))\n",
    "print(np.mean(octopus_suckers))\n",
    "print(\"Variance is:\", my_sample_var(octopus_suckers))\n",
    "print(np.var(octopus_suckers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Implement a third function called `update_mean` that implements the formula whose valdity you proved in Part A. (Note: this function will need to take as its input three things: $x_n$, $\\bar{x}_{n-1}$ and $n$.)\n",
    "\n",
    "Use this function to compute the values that you get from taking the mean of the first suckers count, the first two suckers counts, the first three suckers counts, and so on up to all the suckers counts. Store your means in a numpy array called `sucker_means`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "*** \n",
    "Some claim that the final hours aboard the RMS Titanic were marked by \"class warfare\" in which the people with first-class tickets took all the good spots on the lifeboats; others claim that the final hours were characterized by male chivalry, in which the men valiantly gave up their positions in the boats and succumbed bravely to the depths of the Atlantic. \n",
    "\n",
    "We have the data on survival rates by class and by sex, so let's figure out whether there is evidence for these scenarios. Access the titanic data in `titanic_data.csv` and store it in a Pandas DataFrame. The data contains information pertaining to class status (**Pclass**), survival of passengers (**Survived**), and gender (**Sex**), among others.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  36.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  18.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  14.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  27.0      1   \n",
       "4                           Allen, Mr. William Henry    male  63.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Consider the two claims: class warfare, and male chivalry. Suppose that class warfare occurred in the final hours aboard the Titanic.  What patterns might you expect to see in the data?  Suppose that male chivalry was widespread during the final hours insteas. What patterns might you then expect to see in the data?  Explain both of these hypothesized patterns in words. Are these two hypotheses mutually exclusive or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Part A Answer\n",
    "\n",
    "If class warefare happened in the final hours, then one might expect to see more survivors from first class, and fewer survivors from second and third class. \n",
    "\n",
    "If male chivalry was the case, then one would expect to see more female and children survivors, and fewer male survivors. \n",
    "\n",
    "I would say they are not mutually exclusive. Both instances could have happened, resulting in mostly first class females surviving. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Create a clean data set by removing any rows from the DataFrame that are missing values corresponding to **Survived**, **Pclass**, **Age**, or **Sex**. Store the clean data in a DataFrame called dfTitanic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  36.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  18.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  14.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  27.0      1   \n",
       "4                           Allen, Mr. William Henry    male  63.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTitanic = df.dropna(subset=[\"Survived\", \"Pclass\", \"Age\", \"Sex\"])\n",
    "dfTitanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Determine the fraction of survivors from each passenger class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of survivors from first class: 0.6428571428571429\n",
      "Fraction of survivors from second class: 0.4827586206896552\n",
      "Fraction of survivors from third class: 0.2518703241895262\n"
     ]
    }
   ],
   "source": [
    "class1 = dfTitanic.loc[df[\"Pclass\"]==1]\n",
    "class2 = dfTitanic.loc[df[\"Pclass\"]==2]\n",
    "class3 = dfTitanic.loc[df[\"Pclass\"]==3]\n",
    "\n",
    "class1_survived = dfTitanic.loc[df[\"Pclass\"]==1, \"Survived\"].sum()/len(class1)\n",
    "class2_survived = dfTitanic.loc[df[\"Pclass\"]==2, \"Survived\"].sum()/len(class2)\n",
    "class3_survived = dfTitanic.loc[df[\"Pclass\"]==3, \"Survived\"].sum()/len(class3)\n",
    "\n",
    "\n",
    "print(\"Fraction of survivors from first class:\", class1_survived)\n",
    "print(\"Fraction of survivors from second class:\", class2_survived)\n",
    "print(\"Fraction of survivors from third class:\", class3_survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Compute the fraction of survivors according to class and gender.  Did men in first class or women in third class have a higher survival rate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of male survivors from first class: 0.3770491803278688\n",
      "Fraction of female survivors from first class: 0.9680851063829787\n",
      "Fraction of male survivors from second class: 0.17592592592592593\n",
      "Fraction of female survivors from second class: 0.9342105263157895\n",
      "Fraction of male survivors from third class: 0.14121037463976946\n",
      "Fraction of female survivors from third class: 0.5138888888888888\n"
     ]
    }
   ],
   "source": [
    "class1_male = df.loc[(df[\"Pclass\"]==1) & (df[\"Sex\"]=='male')]\n",
    "class1_female = df.loc[(df[\"Pclass\"]==1) & (df[\"Sex\"]=='female')]\n",
    "\n",
    "class2_male = df.loc[(df[\"Pclass\"]==2) & (df[\"Sex\"]=='male')]\n",
    "class2_female = df.loc[(df[\"Pclass\"]==2) & (df[\"Sex\"]=='female')]\n",
    "\n",
    "class3_male = df.loc[(df[\"Pclass\"]==3) & (df[\"Sex\"]=='male')]\n",
    "class3_female = df.loc[(df[\"Pclass\"]==3) & (df[\"Sex\"]=='female')]\n",
    "\n",
    "class1_males_survived = df.loc[(df[\"Pclass\"]==1) & (df[\"Sex\"]=='male'), \"Survived\"].sum()/len(class1_male)\n",
    "class1_females_survived = df.loc[(df[\"Pclass\"]==1) & (df[\"Sex\"]=='female'), \"Survived\"].sum()/len(class1_female)\n",
    "\n",
    "class2_males_survived = df.loc[(df[\"Pclass\"]==2) & (df[\"Sex\"]=='male'), \"Survived\"].sum()/len(class2_male)\n",
    "class2_females_survived = df.loc[(df[\"Pclass\"]==2) & (df[\"Sex\"]=='female'), \"Survived\"].sum()/len(class2_female)\n",
    "\n",
    "class3_males_survived = df.loc[(df[\"Pclass\"]==3) & (df[\"Sex\"]=='male'), \"Survived\"].sum()/len(class3_male)\n",
    "class3_females_survived = df.loc[(df[\"Pclass\"]==3) & (df[\"Sex\"]=='female'), \"Survived\"].sum()/len(class3_female)\n",
    "\n",
    "print(\"Fraction of male survivors from first class:\", class1_males_survived)\n",
    "print(\"Fraction of female survivors from first class:\", class1_females_survived)\n",
    "\n",
    "print(\"Fraction of male survivors from second class:\", class2_males_survived)\n",
    "print(\"Fraction of female survivors from second class:\", class2_females_survived)\n",
    "\n",
    "print(\"Fraction of male survivors from third class:\", class3_males_survived)\n",
    "print(\"Fraction of female survivors from third class:\", class3_females_survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: How would you characterize the distribution of **AGE**? (By _characterize_ we mean that you should indicate whether the data are unimodal, bimodal, multimodal, symmetric, negatively skewed, positively skewed, etc.)  Make any necessary graphical summaries to justify your conclusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py:4274: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n",
      "/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/__init__.py:1857: RuntimeWarning: invalid value encountered in less_equal\n",
      "  wiskhi = np.compress(x <= hival, x)\n",
      "/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/__init__.py:1864: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  wisklo = np.compress(x >= loval, x)\n",
      "/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/__init__.py:1872: RuntimeWarning: invalid value encountered in less\n",
      "  np.compress(x < stats['whislo'], x),\n",
      "/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/__init__.py:1873: RuntimeWarning: invalid value encountered in greater\n",
      "  np.compress(x > stats['whishi'], x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boxes': [<matplotlib.lines.Line2D at 0x11aadd390>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x11aaddd30>,\n",
       "  <matplotlib.lines.Line2D at 0x11aa2e160>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x11aa2e940>],\n",
       " 'means': [],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x11aa2e550>],\n",
       " 'whiskers': [<matplotlib.lines.Line2D at 0x11aadd4e0>,\n",
       "  <matplotlib.lines.Line2D at 0x11aadd940>]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1125a7d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,4))\n",
    "ax.boxplot(df[\"Age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Were the median and mean ages for females who survived higher or lower than for females who did not survive?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G**: Do the data suggest class warfare, male chivalry, or some combination of both characteristics in the final hours aboard the Titanic?  Justify your conclusion based on the computations done above, or do any other analysis that you like, but be sure to clearly justify your conclusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "There was definitely a combination of both characteristics. Based off of the percentage of survivors based on class, 64% of first class passengers survived compared to 25% of third class. Of the first class survivors, 97% were women. Likewise with second and third class, with 93% and 51% of survivors being women, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 - No arm in another tentacle problem, eh?\n",
    "***\n",
    "\n",
    "_Octopuses have eight arms, which are often called tentacles._ \n",
    "\n",
    "While technically a fact about the noble octopus, this doesn't really do much for the imagination. Go find another octopus fact that you think is cool *and* that you think no one else is likely to report! In fact, *if your fact is unique, you'll earn extra credit on this problem*! Submit your fact [here](https://docs.google.com/forms/d/e/1FAIpQLScjminsyl9Q1d_OswAXHNLKPj9Gu-00qhVsy07VYDZC8d36LQ/viewform?usp=sf_link)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6 - Dirty Data\n",
    "***\n",
    "Access the data from url https://www.stat.berkeley.edu/~statlabs/data/babies.data and store the information in a Pandas DataFrame.  A description of the variables can be found at https://www.stat.berkeley.edu/~statlabs/labs.html.  These data are a subset from a much larger study dealing with child health and development. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bwt</th>\n",
       "      <th>gestation</th>\n",
       "      <th>parity</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>smoke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>64</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>69</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>67</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>136</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>62</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>138</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>62</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>65</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>62</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>143</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>66</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bwt  gestation  parity  age  height  weight  smoke\n",
       "0  120        284       0   27      62     100      0\n",
       "1  113        282       0   33      64     135      0\n",
       "2  128        279       0   28      64     115      1\n",
       "3  123        999       0   36      69     190      0\n",
       "4  108        282       0   23      67     125      1\n",
       "5  136        286       0   25      62      93      0\n",
       "6  138        244       0   33      62     178      0\n",
       "7  132        245       0   23      65     140      0\n",
       "8  120        289       0   25      62     125      0\n",
       "9  143        299       0   30      66     136      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://www.stat.berkeley.edu/~statlabs/data/babies.data\", delim_whitespace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Part A**: Create a clean data set that removes subjects if any observations on the subject are unknown.  Note that that collectors of the data set used values like $9$, $99$, $999$, to denote unknown values.  You can look at the documentation linked in the problem description to determine which unknown-value marker was used for each characteristics.  Store the modified data set in a Pandas DataFrame called dfBabies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'smoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'smoke'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-512f98aff75b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m unknowns = df.loc[(df[\"smoke\"]== '9') & (df[\"parity\"]=='9') & (df[\"bwt\"]=='999') & (df[\"gestation\"]==999) & \n\u001b[0;32m----> 2\u001b[0;31m        (df[\"age\"]=='99') & (df[\"height\"]=='99') & (df[\"weight\"]=='999')]\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'smoke'"
     ]
    }
   ],
   "source": [
    "unknowns = df.loc[(df[\"smoke\"]== '9') & (df[\"parity\"]=='9') & (df[\"bwt\"]=='999') & (df[\"gestation\"]==999) & \n",
    "       (df[\"age\"]=='99') & (df[\"height\"]=='99') & (df[\"weight\"]=='999')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Use the information in dfBabies to create a density histogram of the birth weights of babies whose mothers have never smoked (smoke=0) and another histogram placed directly below the first in the same graphics device for the birth weights of babies whose mothers currently smoke (smoke=1).  Make the range of the horizontal axis $30$ to $180$ (ounces) for both histograms.  Make sure to give each subplot titles and label axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Based on the histograms in **Part B**, characterize the distribution of baby birth weights for both non-smoking and smoking mothers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: What are the mean and median weight difference between babies of smokers and non-smokers?  Can you think of any reason not to use the mean as a measure of center to compare birth weights for this problem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Create side-by-side box-and-whisker plots to compare the birth weights of babies whose mothers never smoked and those who currently smoke.  Use the box-and-whisker plot conventions discussed in lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Using the box-and-whisker plots from **Part E** comment on the distributions of body weights of babies within each smoking / non-smoking groups as well as the comparison of the two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Problem\n",
    "***\n",
    "\n",
    "In every homework assignment we'll give you a Challenge Problem.  Challenge Problems never need to be turned in (and in fact, will not be graded) but we encourage you to give them a shot (after completing the required homework problems) and discuss them with your classmates and your instructors.  \n",
    "\n",
    "In the 1954 book _How to Lie with Statistics_ authors Darrell Huff and Irving Geis describe many common ways that people concoct misleading graphics.  An excerpt from these chapters can be found [here](https://piazza.com/class_profile/get_resource/j6pfvv6b9ze4gi/j771gy7fdpe3e7).  \n",
    "\n",
    "Your job is to go out onto the web and find some data that you find interesting.  Then create both a misleading and a non-misleading version of a graphical summary for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
