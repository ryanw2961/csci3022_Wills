{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CSCI 3022: Intro to Data Science - Fall 2018 Practicum \n",
    "***\n",
    "\n",
    "This practicum is due on Moodle by **11:55pm on Wednesday December 12**. Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  \n",
    "\n",
    "**Here are the rules:** \n",
    "\n",
    "1. All work, code and analysis, must be your own. \n",
    "1. You may use your course notes, posted lecture slides, textbooks, in-class notebooks, and homework solutions as resources.  You may also search online for answers to general knowledge questions like the form of a probability distribution function or how to perform a particular operation in Python/Pandas. \n",
    "1. This is meant to be like a coding portion of your final exam. So, the instructional team will be much less helpful than we typically are with homework. For example, we will not check answers, help debug your code, and so on.\n",
    "1. If something is left open-ended, it is because we want to see how you approach the kinds of problems you will encounter in the wild, where it will not always be clear what sort of tests/methods should be applied. Feel free to ask clarifying questions though.\n",
    "2. You may **NOT** post to message boards or other online resources asking for help.\n",
    "3. You may **NOT** copy-paste solutions *from anywhere*.\n",
    "4. You may **NOT** collaborate with classmates or anyone else.\n",
    "5. In short, **your work must be your own**. It really is that simple.\n",
    "\n",
    "Violation of the above rules will result in an immediate academic sanction (*at the very least*, you will receive a 0 on the practicum or an F in the course, depending on severity), and a trip to the Honor Code Council.\n",
    "\n",
    "**By submitting this assignment, you agree to abide by the rules given above.**\n",
    "\n",
    "***\n",
    "\n",
    "**Name**:  \n",
    "\n",
    "***\n",
    "\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- You may not use late days on the practicum nor can you drop your practicum grade. \n",
    "- If you have a question for us, post it as a **PRIVATE** message on Piazza.  If we decide that the question is appropriate for the entire class, then we will add it to a Practicum clarifications thread. \n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc. \n",
    "- This should go without saying, but... For any question that asks you to calculate something, you **must show all work to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit.\n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Problem 3](#p3)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p1'></a>\n",
    "\n",
    "### [35 points] Problem 1: Yahtzee!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A:** You are playing [Yahtzee](https://en.wikipedia.org/wiki/Yahtzee) with your friends. A player's turn in Yahtzee consists of rolling a set of 5 dice. Then the player is given two additional rolls, where they are allowed to re-roll any number of the dice, including potentially all of them or none of them. The goal is to obtain certain combinations of the dice values resulting after the third roll. Different combinations are worth different amounts of points, and the goal of the game is to get as many points as possible.\n",
    "\n",
    "This game of Yahtzee is a bit unlike any you have ever played before, however. This is because Darth Ketelsen is back, and with her she brought her famous **5-sided dice**. These are fair dice with sides numbered 1-5. So, you are playing Yahtzee with a Sith Lord with 5-sided dice. Indeed, things just got real.\n",
    "\n",
    "A **straight** in Darth Ketelsen's game consists of 5 values all in a row. For example, the outcome $[1,2,3,4,5]$ is a  straight but the outcome $[1,2,3,4,4]$ is not.\n",
    "\n",
    "**Do two things:**\n",
    "1. Compute by hand the probability of rolling a straight in a single roll of all 5 dice. Show all work.\n",
    "2. Write a simulation to verify the probability that you computed. Run at least 10,000 simulations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** The goal of this problem is to compute the probability of getting a straight using all three of your rolls, instead of just the single roll approach that you computed in Part A. Here, we'll need to implement a strategy so that after the first roll and after the second roll, we keep the dice that get us closer to a straight and re-roll the dice that are not useful for our straight.\n",
    "\n",
    "For instance, suppose your first roll comes up $[1,2,3,3,3]$. You really want to get that straight! So, you would follow the strategy of saving the $[1,2,3]$ and re-roll two of the threes, hoping for a 4 and 5 to get the straight. Then, for your third roll, you would save as many of the dice as possible that would be part of a straight, and re-roll any remaining dice.\n",
    "\n",
    "Finish the function below called `dire_straights` to simulate many complete 3-roll turns, and computes the probability of ending your turn with a straight. The only input to the function should be `ntrial`, an integer for the number of turns to simulate. Remember, each turn consists of 3 rolls.\n",
    "\n",
    "Then, use your function to estimate the probability of a straight after a full turn of Yahtzee. Use at least 10,000 simulations, and comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dire_straights(ntrial):\n",
    "    \n",
    "    # your code goes here!\n",
    "        \n",
    "    return 0 # this is a placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C:** Write a simulation to estimate the probability of obtaining a straight if the first roll contains exactly three distinct unique values. For example, a valid first roll could be $[1,5,3,3,3]$ but not $[1,3,3,4,5]$. You are still using the set of 5-sided dice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:** Verify your calculation from Part C by hand. Show all work, and comment on whether the two agree.\n",
    "\n",
    "*Hint: you will need to consider a variety of different cases - what are all the ways you could end up with a straight, given that your first roll contained exactly 3 unique values?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:**  Your friend offers you the following deal. Each time your Yahtzee turn (i.e., all three rolls) results in a 5-of-a-kind, she will give you \\$5. Each time your Yahtzee turn results in a straight, she will give you \\$3. But, she will charge you \\$1 for each turn (where a turn includes all 3 rolls of the five 5-sided dice). Should you take this deal? Fully justify your answer using calculations that include expected values. You may include some simulations to estimate relevant probabilities. Clearly state any assumptions you are making in your modeling choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p2'></a>\n",
    "\n",
    "### [30 points] Problem 2: Sharknado Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governor Hickenlooper has charged you with the task of assessing the factors associated with sharknado risk in Colorado. As everyone knows, sharknadoes are a leading cause of sharknado-related illness, and you are a world-renowned data/shark scientist.\n",
    "\n",
    "You decide to use multiple linear regression to understand and predict what factors lead to increased sharknado hazard. Your lead scientist, aptly named Fin, has collected lots of relevant data at a local sharknado hotspot, the Boulder Reservoir[\\*](#footnote). The data cover a variety of sharknado-related environmental and other conditions, and you'll find this data in the file `sharknadoes.csv`. \n",
    "\n",
    "**Response**: \n",
    "\n",
    "- $\\texttt{sharknado hazard}$: the hazard of a sharknado, where 1 is very unlikely and 100 is highly likely\n",
    "\n",
    "**Features**: \n",
    "\n",
    "- $\\texttt{taunts}$: the number of times over the past year that someone has taunted a shark\n",
    "- $\\texttt{clouds}$: what percentage of the sky was covered by clouds (fraction, 0-1)\n",
    "- $\\texttt{precipitation}$: amount of precipitation in the past 72 hours (inches)\n",
    "- $\\texttt{earthquake}$: the intensity of the most recent earthquake measured in the continental United States\n",
    "- $\\texttt{shark attacks}$: the number of shark attacks within 72 hours prior to the observation\n",
    "- $\\texttt{ice cream sold}$: the number of units of ice cream sold at the beach concession stand \n",
    "- $\\texttt{misery index}$: an economic indicator for how miserable the average United States citizen is, based on the unemployment rate and the inflation rate. More [here](https://www.stuffyoushouldknow.com/podcasts/whats-the-misery-index.htm) and [here](https://en.wikipedia.org/wiki/Misery_index_(economics)). Higher values correspond to more miserable citizens.\n",
    "- $\\texttt{temperature}$: the outside temperature, measured in degrees Fahrenheit\n",
    "- $\\texttt{humidity}$: relative humidity (percent, 0-100)\n",
    "- $\\texttt{pizzas sold}$: the number of pizzas sold at the beach concession stand in the past year\n",
    "- $\\texttt{pressure}$: local air pressure (millibar) \n",
    "- $\\texttt{octopuses}$: the number of octupuses in the vicinity on the day of the observation\n",
    "- $\\texttt{Dan's shoe size}$: the size of the shoes Dan was wearing when the observation was made\n",
    "- $\\texttt{Tony's shoe size}$: the size of the shoes Tony was wearing when the observation was made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Read the data from `sharknadoes.csv` into a Pandas DataFrame.  Note that since we will be doing a multiple linear regression we will need all of the features, so you should drop any row in the DataFrame that is missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Perform the appropriate statistical test at the $\\alpha = 0.01$ significance level to determine if _at least one_ of the features is related to the the response $y$.  Clearly describe your methodology and show all computations in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Write a function `backward_select(df, resp_str, maxsse)` that takes in the DataFrame (`df`), the name of the column corresponding to the response (`resp_str`), and the maximum desired sum of squared errors (`maxsse`), and returns a list of feature names corresponding to the most important features via backward selection.  Use your code to determine the reduced MLR model with the minimal number of features such that the SSE of the reduced model is less than 570. At each stage in backward selection you should remove the feature that has the highest p-value associated with the hypothesis test for the given slope coefficient $\\beta_k \\neq 0$.\n",
    "\n",
    "Your code should clearly indicate which feature was removed in each stage, and the SSE associated with the model fit before the feature's removal. _Specifically, please write your code to print the name of the feature that is going to be removed and the SSE before its removal_. Afterward, be sure to report all of the retained features and the SSE of the reduced model.\n",
    "\n",
    "**Note**: The point of this exercise is to see if you can implement **backward_select** yourself.  You may of course use canned routines like statmodels OLS, but you may not call any Python method that explicitly performs backward selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_select(df, resp_str, maxsse):\n",
    "    \n",
    "    # your code goes here!\n",
    "    \n",
    "    remaining_features = [] # placeholder\n",
    "    \n",
    "    return remaining_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Write down the multiple linear regression model, including estimated parameters, obtained by your backward selection process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Perform the appropriate statistical test at the $\\alpha = 0.01$ significance level to determine whether there is a statistically significant difference between the full model with all features and the reduced model obtained by backward selection in **Part D**. You may use output from your model fit above, but all calculations should be set up in Markdown/MathJax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Based on your conclusions in **Part E**, use the _better_ of the two models to predict the sharknado hazard when the following features are observed: \n",
    "\n",
    "- $\\texttt{taunts}$: 47\n",
    "- $\\texttt{clouds}$: 0.8\n",
    "- $\\texttt{precipitation}$: 1 inch\n",
    "- $\\texttt{earthquake}$: 5\n",
    "- $\\texttt{shark attacks}$: 11\n",
    "- $\\texttt{ice cream sold}$: 120\n",
    "- $\\texttt{misery index}$: 15\n",
    "- $\\texttt{temperature}$: 70 degrees F\n",
    "- $\\texttt{humidity}$: 83\n",
    "- $\\texttt{pizzas sold}$: 5500\n",
    "- $\\texttt{pressure}$: 850 millibar \n",
    "- $\\texttt{octopuses}$: 6\n",
    "- $\\texttt{Dan's shoe size}$: 9.5\n",
    "- $\\texttt{Tony's shoe size}$: 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G:** Consider the model you used in Part E, and consider the fact that you are trying to predict **sharknado hazard**. What is one critical drawback to the MLR model (or any MLR model) for predicting shardnado hazard? What are some modifications that could improve on this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "[Back to top](#top)\n",
    "<a id='p3'></a>\n",
    "\n",
    "### [35 points] Problem 3: FlipMaster5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the file `flips.csv` you'll find the results of an experiment that was conducted with Stella O'Flaherty (the famous octopus data scientist) flipping coins. Her experiment was as follows. \n",
    "\n",
    "1. She reaches into her coin purse and grabs one of two coins, labeled $x$ and $y$. \n",
    "2. She flips her coin until it comes up heads 8 times, and records the coin ID and the number of flips it took to get 8 heads. \n",
    "3. She then replaces the coin in her coin purse and repeats the experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A:**\n",
    "\n",
    "By considering the total number of flips and the total number of \"heads\" in the data file for each coin, estimate the bias of each coin $p_x$ and $p_y$, and use an appropriate statistical test to determine whether the coins have the same bias, i.e. whether $p_x$ and $p_y$ are the same. Perform your test at a significance level that will mistakenly reject the null hypothesis _when that null hypothesis is actually true_ 5% of the time. Report a p-value for your test, and clearly state your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** \n",
    "\n",
    "You learn that, actually, the coin $x$ is from a manufacturer that produces coins whose biases follow some statistical regularity. In particular, the bias of the $x$ coin is in the set $$p_x \\in \\{0.1, 0.2, 0.3, \\dots, 0.9\\}.$$ Furthermore, these biases all occur with equal probability. In other words, $\\tfrac{1}{8}$ of coins have bias $p_x=0.1$, $\\tfrac{1}{8}$ of coins have bias $p_x=0.2$, and so on. \n",
    "\n",
    "For each possible value of $p_x$, compute the probability that Stella's $x$ coin has bias of $p_x$, given the data in her data file. \n",
    "\n",
    "Plot your results with $p_x$ on the horizontal axis and $Pr(p_x \\mid \\text{data})$ on the vertical axis. Make the points or lines that you plot blue. Plots without axis labels will receive zero credit.\n",
    "\n",
    "_Hint_: We have done problems like this before! Think back to how you solved the problem on the midterm where you determined the probability that someone had ESP, given that they guessed the cards correctly. There was a \"rule\", and maybe a \"law\" involved in your calculation..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C:**\n",
    "\n",
    "You learn that, actually, the coin $y$ is from a different manufacturer that produces coins whose biases follow some statistical regularity. In particular, the bias of the $y$ coin is in the set $$p_y \\in \\{0.1, 0.2, 0.3, \\dots, 0.9\\}.$$ Furthermore, these biases all occur with different probability. In particular, the probability that a coin has bias $p_y$ is proportional to $p_y$, which could be written as \n",
    "$$Pr(p_y) \\propto p_y \\quad \\text{for} \\quad p_y \\in \\{0.1, 0.2, 0.3, \\dots, 0.9\\}$$\n",
    "\n",
    "First, write clearly the PMF for $p_y$, based on the information above. \n",
    "\n",
    "Then, for each possible value of $p_y$, compute the probability that Stella's $y$ coin has bias of $p_y$, given the data in her data file. \n",
    "\n",
    "Plot your results with $p_y$ on the horizontal axis and $Pr(p_y \\mid \\text{data})$ on the vertical axis. Make the points or lines that you plot red. Plots without axis labels will receive zero credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:**\n",
    "\n",
    "The information that you have about the manufacturer of coin $x$ and coin $y$ is called _prior information_ since it can influence the estimates of a coin's bias at which you arrive, given the data from the coin's flipping. We often call the distribution $Pr(p_x)$ or $Pr(p_y)$ a _prior distribution_, and call $Pr(p_x \\mid \\text{data})$ or $Pr(p_y \\mid \\text{data})$ a _posterior distribution_, since it represents the estimate that you arrive at after you have taken the data into account. \n",
    "\n",
    "You have already computed posterior distributions for each coin's bias. However, you'll now investigate the importance of the prior by _switching the priors for the two coins_.\n",
    "\n",
    "In other words, using the prior probabilities $Pr(p_x)$, what is your posterior distribution of $Pr(p_y \\mid \\text{data from y})$? Similarly, using the prior probabilities $Pr(p_y)$, what is your posterior distribution of $Pr(p_x \\mid \\text{data from x})$? \n",
    "\n",
    "Create two plots. \n",
    "\n",
    "1. In the first plot, show your results from Part B (the posterior distribution for $p_x$ with the correct prior) plotted with a blue solid line as well as your results from Part D for the posterior distribution for $p_x$ with the incorrect prior with a blue dashed line.  \n",
    "\n",
    "2. In the second plot, show your results from Part C (the posterior distribution for $p_y$ with the correct prior) with a red solid line as well as your results from Part D for the posterior distribution for $p_y$ with the incorrect prior with a red dashed line.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E:**\n",
    "\n",
    "What is the name of the distribution that Stella's experiment is drawn from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "[Back to Problem 2](#p2)\n",
    "\n",
    "<a id='footnote'></a> Yeah yeah - fresh water versus salt water - I know, I know. But sharknadoes also are not real, so..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
